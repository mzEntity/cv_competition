{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip '/content/drive/MyDrive/temp_data/cv_competition_data.zip' -d data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, mode, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): 项目根目录。\n",
    "            mode (string): 模式，包含train, validate, test\n",
    "            transform (callable, optional): 可选的转换操作。\n",
    "        \"\"\"\n",
    "        if transform is None:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "            \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.annotation_path = os.path.join(root_dir, f'data/annotations/{\"val\" if mode == \"test\" else \"train\"}.txt')\n",
    "        self.img_path_dir = os.path.join(root_dir, f'data/{\"val\" if mode == \"test\" else \"train\"}set')\n",
    "        \n",
    "        self.samples = self.get_annotations(mode, self.annotation_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, label = self.samples[idx]\n",
    "        img_path = os.path.join(self.img_path_dir, img_name).replace(\"*\", \"_\")\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (img_name, image), label\n",
    "\n",
    "    def get_annotations(self, mode, annotation_path):\n",
    "        image_labels = []\n",
    "        with open(annotation_path, 'r') as file:\n",
    "            for line in file:\n",
    "                img_name, label = line.strip().split()\n",
    "                image_labels.append((img_name, int(label)))\n",
    "                \n",
    "        count = len(image_labels)\n",
    "        # count = 100\n",
    "        if mode == \"validate\":\n",
    "            image_labels = image_labels[:count//10]\n",
    "        elif mode == \"train\":\n",
    "            image_labels = image_labels[count//10:count]\n",
    "            \n",
    "        return image_labels\n",
    "    \n",
    "def get_dataset(root_dir, mode):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    dataset = CustomDataset(root_dir, mode, transform)\n",
    "    return dataset\n",
    "    \n",
    "    \n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg,(1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 项目根目录\n",
    "root_dir = 'D://fudan//2024Autumn//CV//competition//cv_competition'\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "dataset = CustomDataset(root_dir=root_dir, mode=\"train\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 遍历数据并打印图像和标签的形状\n",
    "for (names, images), labels in dataloader:\n",
    "    print(f'Batch of images shape: {images.shape}')  # 打印图像的形状\n",
    "    print(f'Batch of image names: {names}')  # 打印标签\n",
    "    print(f'Batch of labels: {labels}')  # 打印标签\n",
    "    break  # 只打印一个批次的数据以进行测试\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(dataloader)\n",
    "(names, images), labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print('Labels:\\n', '\\n'.join('%20s: %3d;' % (names[j], labels[j]) for j in range(32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # 输入通道为3 (RGB)，输出通道为32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 # 下采样一半\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), # 卷积层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)                  # 再次下采样\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),                                         # 展平\n",
    "            nn.Linear(64 * 56 * 56, 128),                        # 全连接层\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)                                    # 最终输出单个值（预测年龄）\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class MyResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyResNetModel, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(resnet.fc.in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class MyResNetModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyResNetModel2, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        for param in resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(resnet.fc.in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, train_loader, validate_loader, model, optimizer, criterion, max_epochs, save_path):\n",
    "    \"\"\"\n",
    "    Train the model for regression with early stopping based on validation loss.\n",
    "\n",
    "    Args:\n",
    "        device (torch.device): The device to use for training (e.g., \"cuda\" or \"cpu\").\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        validate_loader (DataLoader): DataLoader for the validation dataset.\n",
    "        model (nn.Module): The model to train.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for model training.\n",
    "        criterion (nn.Module): Loss function for regression (e.g., MSELoss).\n",
    "        max_epochs (int): Maximum number of epochs to train.\n",
    "        save_path (str): Directory to save the best model.\n",
    "    \"\"\"\n",
    "    best_loss = float('inf')\n",
    "    patience = 3  # Stop if no improvement for 3 consecutive epochs\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Training loop\n",
    "        for (names, images), labels in tqdm(train_loader, desc=\"Epoch_\" + str(epoch) + \" Train Processing:\"):\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images).squeeze(1)  # Ensure outputs are 1D\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{max_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        validate_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for (names, images), labels in validate_loader:\n",
    "                images, labels = images.to(device), labels.to(device).float()\n",
    "\n",
    "                outputs = model(images).squeeze(1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                validate_loss += loss.item()\n",
    "\n",
    "        avg_validate_loss = validate_loss / len(validate_loader)\n",
    "        print(f\"Validation Loss: {avg_validate_loss:.4f}\")\n",
    "\n",
    "        is_best = False\n",
    "        # Check for improvement\n",
    "        if avg_validate_loss < best_loss:\n",
    "            print(\"Validation loss improved, saving model...\")\n",
    "            is_best = True\n",
    "            best_loss = avg_validate_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        save_checkpoint(model.state_dict(), save_path, is_best, epoch)\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered. Best validation loss:\", best_loss)\n",
    "            break\n",
    "\n",
    "    print(\"Training complete. Best validation loss:\", best_loss)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(state, save_root, is_best, epoch):\n",
    "    if not os.path.exists(save_root):\n",
    "        os.makedirs(save_root)\n",
    "    save_path = os.path.join(save_root, 'epoch_{}.pth.tar'.format(str(epoch)))\n",
    "    torch.save(state, save_path)\n",
    "    \n",
    "    best_path = os.path.join(save_root, 'best_model.pth.tar'.format(str(epoch)))\n",
    "    torch.save(state, best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start...\")\n",
    "root_dir = '.'\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyResNetModel2().to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = get_dataset(root_dir, \"train\")\n",
    "validate_dataset = get_dataset(root_dir, \"validate\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=False)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=False)\n",
    "\n",
    "train(\n",
    "    device,\n",
    "    train_loader,\n",
    "    validate_loader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    max_epochs=50,\n",
    "    save_path=os.path.join(root_dir, \"save\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
